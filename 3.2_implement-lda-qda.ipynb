{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing _discriminant analysis_ using Python and `numpy` <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Bayes'-theorem\" data-toc-modified-id=\"Bayes'-theorem-1\">Bayes' theorem</a></span></li><li><span><a href=\"#Gaussian-assumption\" data-toc-modified-id=\"Gaussian-assumption-2\">Gaussian assumption</a></span></li><li><span><a href=\"#LDA:-Assume-common-covariance\" data-toc-modified-id=\"LDA:-Assume-common-covariance-3\">LDA: Assume common covariance</a></span></li><li><span><a href=\"#QDA:-Class-specific-covariance\" data-toc-modified-id=\"QDA:-Class-specific-covariance-4\">QDA: Class-specific covariance</a></span></li><li><span><a href=\"#Fitting:-training-predictors-+-training-response---&gt;-model-paramenters\" data-toc-modified-id=\"Fitting:-training-predictors-+-training-response--->-model-paramenters-5\">Fitting: training predictors + training response --&gt; model paramenters</a></span></li><li><span><a href=\"#Predicting:-test-predictors----[model(parameters)]---&gt;-test-response\" data-toc-modified-id=\"Predicting:-test-predictors----[model(parameters)]--->-test-response-6\">Predicting: test predictors -- [model(parameters)] --&gt; test response</a></span></li><li><span><a href=\"#Test-implementation\" data-toc-modified-id=\"Test-implementation-7\">Test implementation</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Fit\" data-toc-modified-id=\"Fit-7.0.1\">Fit</a></span></li><li><span><a href=\"#Fit-with-sklearn\" data-toc-modified-id=\"Fit-with-sklearn-7.0.2\">Fit with sklearn</a></span></li></ul></li><li><span><a href=\"#Test-against-sklearn:-fitting\" data-toc-modified-id=\"Test-against-sklearn:-fitting-7.1\">Test against sklearn: fitting</a></span></li><li><span><a href=\"#Test-against-sklearn:-predictions\" data-toc-modified-id=\"Test-against-sklearn:-predictions-7.2\">Test against sklearn: predictions</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' theorem\n",
    "\n",
    "By Bayes' theorem\n",
    "$$\n",
    "\\begin{align}\n",
    "P(y = k\\ |\\ x) & = \\frac{P(y = k)\\cdot P(x\\ |\\ y = k)}{P(x)}\\\\\n",
    "& = \\frac{\\pi_k P(x\\ |\\ y = k)}{P(x)}\\\\\n",
    "& = \\frac{\\pi_k P(x\\ |\\ y = k)}{\\sum_{l=0}^K\\pi_l P(x\\ |\\ y = k_l)}\\tag{4.10}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "# Gaussian assumption\n",
    "The multivariate Gaussian distribution is described by this function:\n",
    "$$\n",
    "f(x) = \\frac{1}{(2\\pi)^{p/2}|\\mathbf{\\Sigma}|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\mathbf{\\Sigma}^{-1}(x-\\mu)\\right)\\tag{4.18}\n",
    "$$\n",
    "\n",
    "Assume Gaussian distributions of predictors $X$ within each class $k$,\n",
    "$$\n",
    "P(x\\ |\\ y = k_l) = \\frac{1}{(2\\pi)^{p/2}|\\mathbf{\\Sigma}_l|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu_l)^T\\mathbf{\\Sigma}_l^{-1}(x-\\mu_l)\\right)\n",
    "$$\n",
    "\n",
    "Putting into 4.10,\n",
    "$$\n",
    "\\begin{align}\n",
    "P(y = k\\ |\\ x) &= \\frac{\\pi_{k}\\frac{1}{\\cancel{(2\\pi)^{p/2}}|\\mathbf{\\Sigma}_k|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu_k)^T\\mathbf{\\Sigma}_k^{-1}(x-\\mu_k)\\right)}{\\sum_{l=0}^K\\pi_{l} \\frac{1}{\\cancel{(2\\pi)^{p/2}}|\\mathbf{\\Sigma}_l|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu_l)^T\\mathbf{\\Sigma}_l^{-1}(x-\\mu_l)\\right)}\\\\\n",
    "\\mathop{\\mathrm{argmax}}_k P(y = k\\ |\\ x) &= \\mathop{\\mathrm{argmax}}_k \\frac{\\frac{\\pi_{k}}{|\\mathbf{\\Sigma}_k|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu_k)^T\\mathbf{\\Sigma}_k^{-1}(x-\\mu_k)\\right)}{\\sum_{l=0}^K \\frac{\\pi_{l}}{|\\mathbf{\\Sigma}_l|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu_l)^T\\mathbf{\\Sigma}_l^{-1}(x-\\mu_l)\\right)}\\tag{i}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\pi_k$ is the class prior, $\\mu_k$ is the class mean, $\\mathbf{\\Sigma}_k$ is the class specific covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prior(X, y):\n",
    "    '''Return class priors.'''\n",
    "    return np.array([len(X[y==k])/len(X) for k in np.unique(y)])\n",
    "\n",
    "def class_mean(X, y):\n",
    "    '''Return class means.'''\n",
    "    return np.array([np.mean(X[y==k], axis=0) for k in np.unique(y)])\n",
    "\n",
    "def class_cov(X, y):\n",
    "    '''Return class covariances.'''\n",
    "    return np.array([np.cov(X[y==k].T) for k in np.unique(y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA: Assume common covariance\n",
    "For LDA, we assume a common variance between all classes, i.e. $\\mathbf{\\Sigma}_0=\\mathbf{\\Sigma}_1=...\\mathbf{\\Sigma}_K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_cov(X, y):\n",
    "    '''Return shared covariance, weighted by prior.'''\n",
    "    \n",
    "    cov = np.zeros((X.shape[1], X.shape[1]))\n",
    "    priors = class_prior(X, y)\n",
    "    \n",
    "    for k, pi in zip(np.unique(y), priors):\n",
    "        cov += np.cov(X[y==k].T, bias=True)*pi\n",
    "        \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, from (i),\n",
    "$$\n",
    "\\mathop{\\mathrm{argmax}}_k P(y = k\\ |\\ x) = \\mathop{\\mathrm{argmax}}_k \\frac{\\pi_{k}\\exp\\left(-\\frac{1}{2}(x-\\mu_k)^T(\\mathbf{\\Sigma})^{-1}(x-\\mu_k)\\right)}{\\sum_{l=0}^K\\pi_{l} \\exp\\left(-\\frac{1}{2}(x-\\mu_l)^T(\\mathbf{\\Sigma})^{-1}(x-\\mu_l)\\right)}\\\\\n",
    "$$\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\pi \\ge 0 \\because \\text{probability}\\\\\n",
    "\\exp(n) \\gt 0 \\because e \\gt 0\n",
    "\\end{cases}\n",
    "\\implies \\text{denominator} \\ge 0\n",
    "$$\n",
    "\n",
    "And given $\\text{denominator}\\mathrel{\\unicode{x2AEB}} k$,\n",
    "\n",
    "$$\n",
    "\\mathop{\\mathrm{argmax}}_k P(y = k\\ |\\ x) = \\mathop{\\mathrm{argmax}}_k \\pi_{k}\\exp\\left(-(x-\\mu_k)^T(2\\mathbf{\\Sigma})^{-1}(x-\\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "$\\because \\log(x)$ is monotonically increasing,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathop{\\mathrm{argmax}}_k P(y = k\\ |\\ x) &= \\mathop{\\mathrm{argmax}}_k \\log P(y = k\\ |\\ x)\\\\\n",
    "&= \\mathop{\\mathrm{argmax}}_k\\log\\left(\\pi_{k}\\exp\\left(-\\frac{1}{2}(x-\\mu_k)^T(\\mathbf{\\Sigma})^{-1}(x-\\mu_k)\\right)\\right)\\\\\n",
    "&= \\mathop{\\mathrm{argmax}}_k\\left(\\log(\\pi_k) -\\frac{1}{2}(x-\\mu_k)^T\\mathbf{\\Sigma}_k^{-1}(x-\\mu_k)\\right)\\\\\n",
    "&= \\mathop{\\mathrm{argmax}}_k\\left(\\log(\\pi_k) - \\frac{1}{2} x^T \\mathbf{\\Sigma}_k^{-1} x + x^T \\mathbf{\\Sigma}_k^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\mathbf{\\Sigma}_k^{-1} \\mu_k \\right)\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And given $- \\frac{1}{2} x^T \\mathbf{\\Sigma}_k^{-1} x \\mathrel{\\unicode{x2AEB}} k$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathop{\\mathrm{argmax}}_k P(y = k\\ |\\ x) &= \\mathop{\\mathrm{argmax}}_k \\delta_k(x)\\quad\\text{where}\\\\\n",
    "\\delta_k(x) &= x^T \\mathbf{\\Sigma}_k^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\mathbf{\\Sigma}_k^{-1}\\mu_k + \\log(\\pi_k) \\tag{4.19, discriminant}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA: Class-specific covariance\n",
    "For QDA, we do no assume common variance among classes. Thus, from (i), provided that\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\pi \\ge 0 \\because \\text{probability}\\\\\n",
    "|\\mathbf{\\Sigma}|^{-1/2} \\ge 0 \\because \\text{square root}\\\\\n",
    "\\exp(n) \\gt 0 \\because e \\gt 0\n",
    "\\end{cases}\n",
    "\\implies \\text{denominator} \\ge 0\n",
    "$$\n",
    "\n",
    "And given $\\text{denominator}\\mathrel{\\unicode{x2AEB}} k$,\n",
    "\n",
    "$$\n",
    "\\mathop{\\mathrm{argmax}}_k P(y = k\\ |\\ x) = \\mathop{\\mathrm{argmax}}_k\\left(\\frac{\\pi_k}{|\\mathbf{\\Sigma}_k|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu_k)^T\\mathbf{\\Sigma}_k^{-1}(x-\\mu_k)\\right)\\right)\\\\\n",
    "$$\n",
    "\n",
    "$\\because \\log(x)$ is monotonically increasing,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathop{\\mathrm{argmax}}_k P(y = k\\ |\\ x) &= \\mathop{\\mathrm{argmax}}_k \\log P(y = k\\ |\\ x)\\\\\n",
    "&= \\mathop{\\mathrm{argmax}}_k\\log\\left(\\frac{\\pi_k}{|\\mathbf{\\Sigma}_k|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu_k)^T\\mathbf{\\Sigma}_k^{-1}(x-\\mu_k)\\right)\\right)\\\\\n",
    "&= \\mathop{\\mathrm{argmax}}_k\\left(\\log(\\pi_k) - \\frac{1}{2}\\log(|\\mathbf{\\Sigma}_k|) -\\frac{1}{2}(x-\\mu_k)^T\\mathbf{\\Sigma}_k^{-1}(x-\\mu_k)\\right)\\\\\n",
    "&= \\mathop{\\mathrm{argmax}}_k\\left(\\log(\\pi_k) - \\frac{1}{2}\\log(|\\mathbf{\\Sigma}_k|) - \\frac{1}{2} x^T \\mathbf{\\Sigma}_k^{-1} x + x^T \\mathbf{\\Sigma}_k^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\mathbf{\\Sigma}_k^{-1} \\mu_k \\right)\\\\\n",
    "&= \\mathop{\\mathrm{argmax}}_k \\delta_k(x)\\quad\\text{where}\\\\\n",
    "\\delta_k(x) &= \\color{red}{- \\frac{1}{2} x^T \\mathbf{\\Sigma}_k^{-1} x} + x^T \\mathbf{\\Sigma}_k^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\mathbf{\\Sigma}_k^{-1}\\mu_k \\color{red}{- \\frac{1}{2}\\log(|\\mathbf{\\Sigma}_k|)} + \\log(\\pi_k) \\tag{4.23, discriminant}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant(X, prior, mean, cov, quadratic=False):\n",
    "    '''Calculate discriminant delta(X)'''\n",
    "    \n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(1,-1)\n",
    "        \n",
    "    d = np.dot(np.dot(X, np.linalg.pinv(cov)), mean) \\\n",
    "        - np.dot(np.dot(mean.T/2, np.linalg.pinv(cov)), mean) \\\n",
    "        + np.log(prior)\n",
    "    \n",
    "    # Extra terms for QDA (highlighted above in red)\n",
    "    if quadratic:\n",
    "        d -= np.array([np.dot(np.dot(X_i/2, np.linalg.pinv(cov)), X_i.T) \\\n",
    "                       for X_i in X])  # prevent matrix multiplication\n",
    "        d -= np.log(np.linalg.det(cov))/2\n",
    "        \n",
    "    return d\n",
    "\n",
    "def discriminants(X, priors, means, covs, quadratic=False):\n",
    "    '''Calculate discriminant delta_k(X) per class k.'''\n",
    "\n",
    "    dd = np.stack([discriminant(X, prior, mean, cov, quadratic) \\\n",
    "                   for prior, mean, cov in zip(priors, means, covs)], \\\n",
    "                  axis=-1)\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting: training predictors + training response --> model paramenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_fit(X, y):\n",
    "    pi = class_prior(X,y)\n",
    "    mu = class_mean(X,y)\n",
    "    shared_sig = weighted_cov(X,y)\n",
    "    return pi, mu, shared_sig\n",
    "\n",
    "def qda_fit(X, y):\n",
    "    pi = class_prior(X,y)\n",
    "    mu = class_mean(X,y)\n",
    "    sig = class_cov(X,y)\n",
    "    return pi, mu, sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting: test predictors -- [model(parameters)] --> test response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_predict(x, pi, mu, shared_sig):\n",
    "    sig = [shared_sig]*len(pi)  # Duplicate shared covariance.\n",
    "    return np.argmax(discriminants(x, pi, mu, sig), axis=1)\n",
    "\n",
    "def qda_predict(x, pi, mu, sig):\n",
    "    return np.argmax(discriminants(x, pi, mu, sig, quadratic=True), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_observations (n): 150\n",
      "n_predictors (p): 2\n",
      "n_class (k): 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = data.data[:,2:]\n",
    "y = data.target\n",
    "# y = (data.target > 0).astype(int)  # uncomment this for binary classification\n",
    "\n",
    "print(\"n_observations (n): {}\".format(X.shape[0]))\n",
    "print(\"n_predictors (p): {}\".format(X.shape[1]))\n",
    "print(\"n_class (k): {}\".format(len(np.unique(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T11:10:26.279203Z",
     "start_time": "2018-07-30T11:10:25.817565Z"
    }
   },
   "outputs": [],
   "source": [
    "priors_l, means_l, covar_l = lda_fit(X, y)\n",
    "priors_q, means_q, covars_q = qda_fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T11:10:26.355036Z",
     "start_time": "2018-07-30T11:10:26.281406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariance=True, store_covariances=None, tol=0.0001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "clf_l = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "clf_q = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "clf_l.fit(X,y)\n",
    "clf_q.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test against sklearn: fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T11:10:26.786875Z",
     "start_time": "2018-07-30T11:10:26.782580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn LDA parameters:\n",
      " priors: [0.33333333 0.33333333 0.33333333] \n",
      " means: [[1.464 0.244]\n",
      " [4.26  1.326]\n",
      " [5.552 2.026]] \n",
      " covariance: [[0.18146667 0.04169067]\n",
      " [0.04169067 0.04117067]]\n",
      "\n",
      " my LDA parameters:\n",
      " priors: [0.33333333 0.33333333 0.33333333] \n",
      " means: [[1.464 0.244]\n",
      " [4.26  1.326]\n",
      " [5.552 2.026]] \n",
      " covariance: [[0.18146667 0.04169067]\n",
      " [0.04169067 0.04117067]]\n",
      "\n",
      " sklearn QDA parameters:\n",
      " priors: [0.33333333 0.33333333 0.33333333] \n",
      " means: [[1.464 0.244]\n",
      " [4.26  1.326]\n",
      " [5.552 2.026]] \n",
      " covariance: [[[0.03010612 0.00569796]\n",
      "  [0.00569796 0.01149388]]\n",
      "\n",
      " [[0.22081633 0.07310204]\n",
      "  [0.07310204 0.03910612]]\n",
      "\n",
      " [[0.30458776 0.04882449]\n",
      "  [0.04882449 0.07543265]]]\n",
      "\n",
      " my QDA parameters:\n",
      " priors: [0.33333333 0.33333333 0.33333333] \n",
      " means: [[1.464 0.244]\n",
      " [4.26  1.326]\n",
      " [5.552 2.026]] \n",
      " covariance: [[[0.03010612 0.00569796]\n",
      "  [0.00569796 0.01149388]]\n",
      "\n",
      " [[0.22081633 0.07310204]\n",
      "  [0.07310204 0.03910612]]\n",
      "\n",
      " [[0.30458776 0.04882449]\n",
      "  [0.04882449 0.07543265]]]\n"
     ]
    }
   ],
   "source": [
    "print('sklearn LDA parameters:\\n', 'priors:',clf_l.priors_, \n",
    "      '\\n means:', clf_l.means_, \n",
    "      '\\n covariance:', clf_l.covariance_)\n",
    "\n",
    "print('\\n my LDA parameters:\\n', 'priors:', priors_l, \n",
    "      '\\n means:', means_l, \n",
    "      '\\n covariance:', covar_l)\n",
    "\n",
    "print('\\n sklearn QDA parameters:\\n', 'priors:',clf_q.priors_, \n",
    "      '\\n means:', clf_q.means_, \n",
    "      '\\n covariance:', np.array(clf_q.covariance_))\n",
    "\n",
    "print('\\n my QDA parameters:\\n', 'priors:', priors_q, \n",
    "      '\\n means:', means_q, \n",
    "      '\\n covariance:', covars_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test against sklearn: predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T11:10:27.307192Z",
     "start_time": "2018-07-30T11:10:27.303140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA predictions match: True\n",
      "QDA predictions match: True\n"
     ]
    }
   ],
   "source": [
    "my_predict_l = lda_predict(X, priors_l, means_l, covar_l)\n",
    "sklearn_predict_l = clf_l.predict(X)\n",
    "\n",
    "print('LDA predictions match:', (my_predict_l == sklearn_predict_l).all())\n",
    "\n",
    "my_predict_q = qda_predict(X, priors_q, means_q, covars_q)\n",
    "sklearn_predict_q = clf_q.predict(X)\n",
    "\n",
    "print('QDA predictions match:', (my_predict_q == sklearn_predict_q).all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
