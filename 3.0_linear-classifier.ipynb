{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification\n",
    "### SLM003 06/08/2018\n",
    "\n",
    "References:\n",
    "\n",
    "`ISL04` James G., Witten D., Hastie T., Tibshirani R. (2013) **Classification**. In: _An Introduction to Statistical Learning_. Springer Texts in Statistics, vol 103. Springer, New York, NY. doi: https://doi.org/10.1007/978-1-4614-7138-7_4\n",
    "\n",
    "`ESL04` Hastie T., Tibshirani R., Friedman J. (2009) **Linear Methods for Classification**. In: _The Elements of Statistical Learning_ (2nd ed.). Springer Series in Statistics. Springer, New York, NY. doi: https://doi.org/10.1007/978-0-387-84858-7_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "1. Logistic regression\n",
    "2. Discriminant analysis\n",
    "  1. Linear discriminant analysis (LDA)\n",
    "  2. Quadratic discriminant analysis (QDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is \"classification\"?\n",
    "\n",
    "- **Supervised learning**: use inputs to predict output\n",
    "- Classification predicts _**qualitative**_ (a.k.a. _categorical_, _discrete_) outputs\n",
    "- Input: _**predictors**_ (a.k.a. _features_, _independent variables_, $X$) -- quantitative and/or qualitative\n",
    "- Output: _**response**_ (a.k.a. _target_, _dependent variable_, $y$)\n",
    "  - which may be refered to as different _response levels_, _targets_, _**classes**_, _categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic regression\n",
    "\n",
    "Goal: describe predictor-response relationship using the **logistic model**\n",
    "\n",
    "The _logistic function_ is defined as:\n",
    "$$\n",
    "p(X) = \\frac{\\exp(\\beta_0 + \\beta_1 X_1 + ... + \\beta_p X_p)}{1 + \\exp(\\beta_0 + \\beta_1 X_1 + ... + \\beta_p X_p)}\\tag{4.6}\n",
    "$$\n",
    "\n",
    "- $p(X)$: predicted response\n",
    "- $X_i$: predictors\n",
    "- $\\beta_i$: parameters of the model\n",
    "  - $\\beta_0$: _intercept_\n",
    "  - other $\\beta_i$: _coefficients_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import mpl_toolkits.mplot3d.art3d as art3d\n",
    "from matplotlib.patches import Rectangle\n",
    "from ipywidgets import interactive, Button\n",
    "from sklearn import datasets\n",
    "from slm import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fitting a logistic model to binary response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_observations (n): 150\n",
      "n_predictors (p): 1\n",
      "n_class (k): 2\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "\n",
    "dataX = data.data[:,:1]\n",
    "dataY = (data.target > 0).astype(int)\n",
    "print(\"n_observations (n): {}\".format(dataX.shape[0]))\n",
    "print(\"n_predictors (p): {}\".format(dataX.shape[1]))\n",
    "print(\"n_class (k): {}\".format(len(np.unique(dataY))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def logistic(x: float) -> float:\n",
    "    '''Take linear, return logistic.'''\n",
    "    return np.exp(x) / (1 + np.exp(x))\n",
    "\n",
    "def logreg_predict(x, coeff, intercept):\n",
    "    return logistic(np.dot(x, coeff.T).squeeze() + intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_logistic(beta0=-15, beta1=3):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,6))\n",
    "    X = np.linspace(0, 10, 50)\n",
    "    Y = beta0 + beta1*X\n",
    "    ax[0].plot(X, Y, c='grey')\n",
    "    ax[0].set_xlim(0,10)\n",
    "    ax[0].set_ylim(-40,40)\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_title('Logit', fontsize=15)\n",
    "    ax[0].set_ylabel(r'$\\log\\frac{p(X)}{1-p(X)}=\\beta_0+\\beta_1X$', fontsize=15)\n",
    "    ax[1].plot(X, logistic(Y), c='grey')\n",
    "    precision = dataY==np.round(logistic(beta0+beta1*dataX).squeeze())\n",
    "    cim = ax[1].scatter(dataX, dataY, s=80, marker='o',\\\n",
    "                        c=precision, \\\n",
    "                        cmap=cm.get_cmap('seismic_r', 2))\n",
    "    cim.set_facecolor('none')\n",
    "    ax[1].set_xlim(3,9)\n",
    "    ax[1].set_ylim(-0.5,1.5)\n",
    "    ax[1].set_yticks([0,1])\n",
    "    ax[1].set_xlabel('x', fontsize=15)\n",
    "    ax[1].set_ylabel(r'p(x)', fontsize=15)\n",
    "    ax[1].set_title('Logistic model', fontsize=15)\n",
    "    ax[1].text(3.2,1.3, 'Error rate: {:.3}'.format(\n",
    "        1-len(precision.nonzero()[0])/len(precision)), fontsize=15)\n",
    "    cax = plt.colorbar(cim)\n",
    "    cax.set_ticks([0.25, 0.75])\n",
    "    cax.ax.set_yticklabels(['incorrect', 'correct'])\n",
    "    plt.show()\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "fit_logreg = interactive(plot_logistic, beta0=(-40., 40.), beta1=(-10.,10.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33abf602cff44218b079f8aafadc47ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-15.0, description='beta0', max=40.0, min=-40.0), FloatSlider(value=3.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fit_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Fitting a logistic function to binary response, with 2 predictors ($p = 2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_observations (n): 150\n",
      "n_predictors (p): 2\n",
      "n_class (k): 2\n"
     ]
    }
   ],
   "source": [
    "dataX = data.data[:,:2]\n",
    "dataY = (data.target > 0).astype(int)\n",
    "print(\"n_observations (n): {}\".format(dataX.shape[0]))\n",
    "print(\"n_predictors (p): {}\".format(dataX.shape[1]))\n",
    "print(\"n_class (k): {}\".format(len(np.unique(dataY))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_logistic_2d(beta0=-1, beta1=3, beta2=-5, azim=-123, elev=16):\n",
    "    X = np.vstack((np.linspace(0, 10, 100), np.linspace(0, 10, 100))).T\n",
    "    X_mesh = viz.make_mesh(X, 0.1)\n",
    "    Y = np.dot(X_mesh, np.array([beta1, beta2]).T).squeeze() + beta0\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    \n",
    "    ax = fig.add_subplot(2,3,1)\n",
    "    ax.plot(X_mesh[:,1,1], Y[:,0], lw=1, c='grey')\n",
    "    ax.set_title('Logit', fontsize=15)\n",
    "    ax.set_xlabel('$x_0$', fontsize=15)\n",
    "    ax.set_xlim(0,10)\n",
    "    ax.set_ylim(-40,40)\n",
    "    ax.set_ylabel(r'$\\log\\frac{p(X)}{1-p(X)}$', fontsize=15)\n",
    "    ax.text(0, 40, '$where\\ x_1=0$', fontsize=15, verticalalignment='top')\n",
    "    \n",
    "    ax = fig.add_subplot(2,3,4)\n",
    "    ax.plot(X_mesh[0,:,0], Y[0,:], lw=1, c='grey')\n",
    "    ax.set_xlim(0,10)\n",
    "    ax.set_ylim(-40,40)\n",
    "    ax.set_xlabel('$x_1$', fontsize=15)\n",
    "    ax.set_ylabel(r'$\\log\\frac{p(X)}{1-p(X)}$', fontsize=15)\n",
    "    ax.text(0, 40, '$where\\ x_0=0$', fontsize=15, verticalalignment='top')\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,(2,3), projection='3d')\n",
    "    logy = logistic(Y)\n",
    "    logy[X_mesh[...,0]<3] = np.nan\n",
    "    logy[X_mesh[...,0]>9] = np.nan\n",
    "    logy[X_mesh[...,1]<2] = np.nan\n",
    "    logy[X_mesh[...,1]>5] = np.nan\n",
    "    ax.plot_wireframe(X_mesh[...,0], X_mesh[...,1], \n",
    "                         logy, \n",
    "                         color=\"grey\", alpha=0.5, lw=1, rcount=40, ccount=40)\n",
    "    precision = dataY==np.round(logreg_predict(dataX, np.array([beta1, beta2]), beta0).squeeze())\n",
    "    cim = ax.scatter(dataX[:,0], dataX[:,1], dataY, s=20, marker='o',\\\n",
    "                        c=precision, \\\n",
    "                        cmap=cm.get_cmap('seismic_r', 2))\n",
    "    cim.set_facecolor('none')\n",
    "    ax.set_xlim(3,9)\n",
    "    ax.set_ylim(2,5)\n",
    "    ax.set_zlim(0,1)\n",
    "    cax = plt.colorbar(cim)\n",
    "    cax.set_ticks([0.25, 0.75])\n",
    "    cax.ax.set_yticklabels(['incorrect', 'correct'])\n",
    "    ax.view_init(elev, azim)\n",
    "    ax.set_title('Logisitc model\\nError rate: {:.3}'.format(\n",
    "        1-len(precision.nonzero()[0])/len(precision)), fontsize=15)\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel('$x_0$', fontsize=15)\n",
    "    ax.set_ylabel('$x_1$', fontsize=15)\n",
    "    ax.set_zlabel('p(x)', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "fit_logreg_2d = interactive(plot_logistic_2d, beta0=(-40., 40.), beta1=(-10.,10.), beta2=(-10.,10.),\n",
    "                azim=(-180,180, 22.5), elev=(-180,180, 22.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b062bf199b5e44f3b52e6446b9cc2030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-1.0, description='beta0', max=40.0, min=-40.0), FloatSlider(value=3.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(fit_logreg_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fitting the logistic model using \"maximum likelihood\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too slow, first test if binder is fast enough\n",
    "oh could be a RISExJupyterNotebook thing, try Lab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discriminant analysis"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "autolaunch": false,
   "height": "90%",
   "progress": "enable",
   "theme": "white",
   "width": "70%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
